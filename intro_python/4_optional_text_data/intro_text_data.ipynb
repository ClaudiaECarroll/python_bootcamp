{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"12m1-TAO_GbNqm1d2KyHcUG_6tNnyN-Lm","timestamp":1747100285705}],"mount_file_id":"1CUdKaZvehbXTdBFAvvmxiRy_93PkA030","authorship_tag":"ABX9TyO3h6N/Td2uvXlwapW3eMQm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Reading and Processing Text Files\n","\n","Introducing:\n","\n","\n","\n","*   Loading text files\n","*   Tokenization and Cleaning\n","*   Word Frequency Analysis\n","\n"],"metadata":{"id":"ER98tX-C5z7U"}},{"cell_type":"code","source":["import os\n","\n","snow_white = open(\"/content/drive/MyDrive/python_bootcamp/sample_data/snow-white_and_rose-red.txt\", encoding=\"utf-8\").read()"],"metadata":{"id":"m0H8qYxaAGDe","executionInfo":{"status":"ok","timestamp":1747102638482,"user_tz":300,"elapsed":211,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["print(snow_white)"],"metadata":{"id":"KrpzfijgAINW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Cleaning and Pre-processing ##"],"metadata":{"id":"_DtGzAsCCWiP"}},{"cell_type":"code","source":["#Removing bibliographic text\n","\n","snow_white_cleaned = [snow_white.split(\"*****\")[0]][0]"],"metadata":{"id":"5QKoOqFtByn5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(snow_white_cleaned)"],"metadata":{"id":"2ka3U0KXB_PI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Tokenization\n","\n","import nltk\n","nltk.download('punkt_tab')\n","from nltk.tokenize import sent_tokenize, word_tokenize\n","\n"],"metadata":{"id":"XKwec5RPCKUO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Extract tokens\n","tokens = word_tokenize(snow_white_cleaned)\n","print(tokens)"],"metadata":{"id":"MIry3WjpC5o-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(tokens)"],"metadata":{"id":"3yqrMlouG1Yv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Remove punctuation\n","\n","import string\n","\n","punctuation = list(string.punctuation)\n","\n","punctuation.append(\"‘\")\n","punctuation.append(\"’\")\n","punctuation.append(\"“\")\n","punctuation.append(\"”\")\n","print(punctuation)\n"],"metadata":{"id":"a_oN6H4jDiz7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for token in tokens:\n","  if token in punctuation:\n","    tokens.remove(token)\n"],"metadata":{"id":"chZRNpGJEKzt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(tokens)"],"metadata":{"id":"EgOke5YcG7EN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(tokens)"],"metadata":{"id":"MZ-9Zv9eEy0b"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Manually removing remaining curly quotes from the tokens list (alternative way to remove punctuation)\n","\n","tokens = [token for token in tokens if token.isalpha()]\n"],"metadata":{"id":"orwTwEzbH5uD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Make all lowercase\n","\n","tokens = [token.lower() for token in tokens]\n","print(tokens)"],"metadata":{"id":"F4ueIe8OFHR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculate word count\n","\n","word_count = len(tokens)\n","print(word_count)"],"metadata":{"id":"GJsO3PBPJB3I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Calculate most frequent words\n","\n","from collections import Counter\n","\n","word_counts = Counter(tokens)\n","print(word_counts)"],"metadata":{"id":"oTeG9uAYFThs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Remove stopwords\n","\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","stopwords = stopwords.words(\"english\")\n","print(stopwords)\n","\n"],"metadata":{"id":"5-ndJQgwFjlt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_words = [token for token in tokens if token not in stopwords]\n","print(content_words)"],"metadata":{"id":"cjiKtSZ_HocU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["len(content_words)"],"metadata":{"id":"gugtaudKJKra"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["content_word_counts = Counter(content_words)\n","print(content_word_counts)"],"metadata":{"id":"bnbfQejBHwDc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","df = pd.DataFrame.from_dict(content_word_counts, orient=\"index\",\n","                            columns=[\"count\"])\n","df.sort_values(\"count\", ascending=False, inplace=True)\n","print(df)\n"],"metadata":{"id":"O_MPAIqhIQw3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Exercises!**\n","\n","\n","\n"],"metadata":{"id":"JVzD0TCMI1AK"}},{"cell_type":"markdown","source":["## Exercise: Text Files\n","\n","Create a new text file called “python.txt” that contains the text “I am almost finished my first python class!”)"],"metadata":{"id":"thK1_CiRXFcR"}},{"cell_type":"code","source":["file = open(\"python.txt\", mode=\"w\", encoding=\"utf-8\")\n","file.write(\"I am almost finished my first python class!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Hb4BlAVXWLq","executionInfo":{"status":"ok","timestamp":1747101527905,"user_tz":300,"elapsed":8,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}},"outputId":"75411e9c-96b1-4ef6-eec9-78239564e51b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["## Exercise: Word Frequencies\n","\n","Write the code to count the approximate number of words in the file austen_pride.txt"],"metadata":{"id":"9xS0SjzVWuRG"}},{"cell_type":"code","source":["# Exercise: Word Frequencies -- Solution\n","\n","import nltk\n","from nltk.tokenize import word_tokenize\n","nltk.download('punkt_tab')\n","\n","file = open(\"/content/drive/MyDrive/python_bootcamp/sample_data/austen_pride.txt\", mode=\"r\", encoding=\"utf-8\")\n","text = file.read()\n","tokens = word_tokenize(text)\n","tokens = [token.lower() for token in tokens if token.isalpha()]\n","print(len(tokens))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ck48kpsWkLM","executionInfo":{"status":"ok","timestamp":1747101772524,"user_tz":300,"elapsed":1430,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}},"outputId":"4f0fe9b3-2ecb-427a-b909-59bf868c499a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["120201\n"]}]},{"cell_type":"markdown","source":["## Exercise: Relative Frequencies\n","\n","Calculate and compare the relative frequency of male pronouns to the relative frequency of female pronouns in rapunzel.txt"],"metadata":{"id":"ZnzAis--Wjyx"}},{"cell_type":"code","source":["# Tokenizing the text file\n","\n","rapunzel = open(\"/content/drive/MyDrive/python_bootcamp/sample_data/rapunzel.txt\", encoding=\"utf-8\").read()\n","\n","tokens = word_tokenize(rapunzel)"],"metadata":{"id":"Gvus3So5Iajj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking if pronouns are stopwords or not\n","\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","stopwords = stopwords.words(\"english\")\n","print(stopwords)\n","\n","if \"her\" in stopwords:\n","  print(\"It's a stopword\")\n","else:\n","  print(\"It's not a stopword\")"],"metadata":{"id":"poAzYifH5UKf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747102304652,"user_tz":300,"elapsed":28,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}},"outputId":"2b783f62-b611-4fcf-a7e2-8f062d4649c9"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n","It's a stopword\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}]},{"cell_type":"code","source":["#stop_words = set(stopwords.words('english'))\n","\n","female_pronouns = [\"she\", \"her\", \"hers\", \"herself\"]\n","male_pronouns = [\"he\", \"him\", \"his\", \"himself\"]\n","\n","pronouns = female_pronouns + male_pronouns\n","\n","# Example: remove \"not\" from the stopword list\n","for word in pronouns:\n","    stopwords.remove(word)\n"],"metadata":{"id":"Cwqv1mOuZtBB","executionInfo":{"status":"ok","timestamp":1747102338415,"user_tz":300,"elapsed":28,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["# Cleaning tokens of punctuation, and making all lowercase\n","\n","import string\n","\n","punctuation = list(string.punctuation)\n","\n","punctuation.append(\"‘\")\n","punctuation.append(\"’\")\n","\n","token = [token.lower for token in tokens if token not in punctuation]"],"metadata":{"id":"0j8539aX4-H0","executionInfo":{"status":"ok","timestamp":1747102406006,"user_tz":300,"elapsed":10,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["# Actually calculating the relative frequencies\n","\n","female_pronoun_count = 0\n","\n","for x in female_pronouns:\n","  for y in tokens:\n","    if x == y:\n","      female_pronoun_count += 1\n","\n","male_pronoun_count = 0\n","\n","for x in male_pronouns:\n","  for y in tokens:\n","     if x == y:\n","      male_pronoun_count += 1\n","\n","relative_female_freq = female_pronoun_count / len(tokens)\n","relative_male_freq = male_pronoun_count / len(tokens)\n","\n","print(\"The relative frequency of female pronouns is: \" + str(relative_female_freq))\n","print(\"The relative frequency of male pronouns is: \" + str(relative_male_freq))"],"metadata":{"id":"3U_oxEDQxIwE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747102413360,"user_tz":300,"elapsed":42,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}},"outputId":"9fb921bb-c1ce-403e-eb79-02a13aebac39"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["The relative frequency of female pronouns is: 0.036275695284159616\n","The relative frequency of male pronouns is: 0.03083434099153567\n"]}]},{"cell_type":"code","source":["# Alternative using Counter\n","\n","from collections import Counter\n","\n","token_counts = Counter(tokens)\n","\n","female_pronoun_count = 0\n","for pronoun in female_pronouns:\n","    female_pronoun_count += token_counts[pronoun]\n","\n","male_pronoun_count = 0\n","for pronoun in male_pronouns:\n","    male_pronoun_count += token_counts[pronoun]\n","\n","relative_female_freq = female_pronoun_count / len(tokens)\n","relative_male_freq = male_pronoun_count / len(tokens)\n","\n","print(\"The relative frequency of female pronouns is:\", relative_female_freq)\n","print(\"The relative frequency of male pronouns is:\", relative_male_freq)\n"],"metadata":{"id":"2-5tUiq_UEVJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747102555448,"user_tz":300,"elapsed":13,"user":{"displayName":"Claudia Carroll","userId":"06718749990751034587"}},"outputId":"c61b83b9-b4ce-4757-b8d5-798b29a47ab6"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["The relative frequency of female pronouns is: 0.036275695284159616\n","The relative frequency of male pronouns is: 0.03083434099153567\n"]}]}]}